# RadAI Chat External Deployment Instructions

This guide explains how to set up RadAI Chat to work from external domains like `radiology.haydd.com` while connecting to your local LM Studio server.

## ğŸŒ Problem

When accessing RadAI Chat from an external domain (like `radiology.haydd.com`), the browser blocks direct API calls to your local server (`192.168.2.180:5000`) due to CORS (Cross-Origin Resource Sharing) restrictions and network policies.

## âœ… Solution

Use a PHP proxy on your external server to forward API requests to your local LM Studio server.

## ğŸ“ Files to Upload to radiology.haydd.com

Upload these files to your external web server:

```
radiology.haydd.com/
â”œâ”€â”€ index.html
â”œâ”€â”€ styles.css
â”œâ”€â”€ script.js
â”œâ”€â”€ config.js
â”œâ”€â”€ manifest.json
â”œâ”€â”€ sw.js
â”œâ”€â”€ api.php          â† This is the key proxy file
â””â”€â”€ paste-test.html  (optional)
```

## ğŸ”§ Setup Steps

### 1. Upload Files to External Server

Upload all the RadAI Chat files to your `radiology.haydd.com` server, including the new `api.php` file.

### 2. Configure the PHP Proxy

The `api.php` file is already configured to connect to your LM Studio server at `192.168.2.64:1234`. 

If you need to change the LM Studio address, edit this line in `api.php`:
```php
$LM_STUDIO_BASE_URL = 'http://192.168.2.64:1234';
```

### 3. Test the Setup

1. **Access locally**: `http://localhost:5000` (should use direct proxy)
2. **Access externally**: `https://radiology.haydd.com` (should use PHP proxy)

## ğŸ” How It Works

### Local Access (localhost:5000)
```
Browser â†’ Your Python Server (/api) â†’ LM Studio (192.168.2.64:1234)
```

### External Access (radiology.haydd.com)
```
Browser â†’ External Server (api.php) â†’ LM Studio (192.168.2.64:1234)
```

## ğŸ§ª Testing

### Test External Connectivity

1. **Visit**: `https://radiology.haydd.com/api.php?path=v1/models`
2. **Expected**: JSON response with available models
3. **If it fails**: Check if radiology.haydd.com can reach your network

### Test Chat Functionality

1. **Open**: `https://radiology.haydd.com`
2. **Check console**: Should show "External access via PHP proxy"
3. **Send message**: Should work normally

## âš ï¸ Network Requirements

For external access to work, your external server must be able to reach your LM Studio server:

- **Option A**: LM Studio server has public IP access
- **Option B**: External server is on same network/VPN
- **Option C**: Network routing allows externalâ†’internal connections

## ğŸ”’ Security Considerations

1. **Firewall**: Ensure LM Studio server allows connections from external server
2. **Authentication**: Consider adding API key authentication to api.php
3. **Rate Limiting**: Consider adding rate limiting to prevent abuse
4. **HTTPS**: Use HTTPS for production deployment

## ğŸ› Troubleshooting

### "Failed to get response from AI model"

1. **Check PHP proxy**: Visit `/api.php?path=v1/models` directly
2. **Check network**: Can external server reach `192.168.2.64:1234`?
3. **Check LM Studio**: Is it running and accessible?
4. **Check browser console**: Look for detailed error messages

### CORS Errors

- Should be resolved by the PHP proxy
- If still occurring, check if api.php is properly configured

### Connection Timeouts

- Increase timeout in api.php (currently 60 seconds)
- Check network latency between servers

## ğŸ“Š Monitoring

The JavaScript automatically tests connectivity on startup and shows:
- âœ… Success: Normal operation
- âš ï¸ Warning: Connectivity issues detected

## ğŸš€ Production Deployment

For production use:

1. **Use HTTPS** for security
2. **Add authentication** to api.php
3. **Monitor performance** and add caching if needed
4. **Set up proper error logging**
5. **Configure backup LM Studio servers**

---

Your RadAI Chat should now work from both local and external access points!
